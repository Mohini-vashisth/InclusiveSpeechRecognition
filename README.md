
# Inclusive Speech Recognition: A Real-Time Transcription System for Individuals with Speech Impediments

This project aims to build a real-time transcription system optimized for individuals with speech impediments, using OpenAI Whisper for transcription and a fine-tuned T5 model for correction.

---

## ğŸ“Œ Project Overview

This project provides an inclusive speech-to-text transcription system by improving automatic speech recognition (ASR) performance for individuals with speech impediments like dysarthria. The approach combines **Whisper** for transcription and **T5** for error correction.

---

## ğŸ“‚ Project Structure

```
InclusiveSpeechRecognition/
â”œâ”€â”€ venv/                           # Python virtual environment (Not pushed to GitHub)
â”œâ”€â”€ models/                         # Directory for trained models
â”‚   â””â”€â”€ t5_correction_model/        # Fine-tuned T5 model for transcription correction
â”œâ”€â”€ main.py                         # Real-time transcription and correction script
â”œâ”€â”€ train_correction_model.py       # Training script for fine-tuning T5 model
â”œâ”€â”€ generate_correction_data.py     # Generates Whisper correction dataset
â”œâ”€â”€ evaluate_corrections.py         # Evaluates model performance using WER and CER
â”œâ”€â”€ whisper_correction_data.csv     # Generated training data (Ignored by .gitignore)
â”œâ”€â”€ requirements.txt                # Python dependencies
â”œâ”€â”€ README.md                       # Project description and usage guide
â”œâ”€â”€ .gitignore                      # Files and folders to exclude from version control
```

---

## ğŸ” Models Used

1. **Whisper (Base)**: For transcription.  
2. **T5-small (Fine-tuned)**: For correcting transcription errors.

---

## ğŸ“Š Evaluation Metrics

- **Word Error Rate (WER)**
- **Character Error Rate (CER)**

---

## ğŸ“¦ Installation

Clone the repository and install dependencies.

```bash
git clone https://github.com/YourUsername/InclusiveSpeechRecognition.git
cd InclusiveSpeechRecognition
python3 -m venv venv
source venv/bin/activate  # On Windows, use .\venv\Scripts\activate
pip install -r requirements.txt
```

---

## ğŸš€ Usage

### 1. Generate Correction Data
To prepare the training dataset from the TORGO dysarthric subset:
```bash
python generate_correction_data.py
```

### 2. Train the Model
To fine-tune the T5 model on the correction dataset:
```bash
python train_correction_model.py
```

### 3. Evaluate the Model
To calculate WER and CER on the test set:
```bash
python evaluate_corrections.py
```

### 4. Run the Real-Time Application
To use the trained model for real-time transcription and correction:
```bash
python main.py
```

---

## ğŸ“Œ Future Improvements

- Adding a GUI using **Streamlit or Tkinter** for ease of use.
- Training on larger datasets for better performance.
- Model personalization for specific speakers with severe speech impediments.

---

## ğŸ’» Author

- **Mohini Vashisth**  

---

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.
